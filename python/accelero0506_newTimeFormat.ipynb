{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "9306a56d-a7f3-43a1-a58e-06310cbc1b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redis_db():    \n",
    "    rds = redis.StrictRedis(host='docker.vm', port=6379, db=15)\n",
    "    for key in rds.scan_iter(\"*\"):\n",
    "        rds.delete(key)\n",
    "#remove_redis_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "39ecdb36-fd6b-4710-9e45-1f22c51bfb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "def get_raw_data():\n",
    "    rds = redis.StrictRedis(host='docker.vm', port=6379, db=14)\n",
    "    for key in rds.scan_iter(\"data_raw:*\"):\n",
    "        Accelerations=rds.get(key).decode('ascii').split(\",\")        \n",
    "        Accelerations=[int(v) for v in Accelerations]\n",
    "        \n",
    "        assert len(Accelerations) %3 ==0, f\"data corrupt with key {key}\"\n",
    "        \n",
    "        all_accelerometer,all_time=chop_data_to_slice(Accelerations)\n",
    "        for a_chunk,time_chunk in zip(all_accelerometer,all_time):\n",
    "            yield a_chunk,time_chunk            \n",
    "    yield None,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cde993ef-11f8-4147-a543-5d3f26a58600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 把加速度数据切割成不同的段\n",
    "#2. 时间重整化，t0时刻设置为0\n",
    "#chop into data slice\n",
    "def chop_data_to_slice(a_):\n",
    "    all_accelerometer,all_time=[],[]\n",
    "    while len(a_)>0:\n",
    "        start_time,end_time,length=a_[0],a_[1],a_[2]\n",
    "        data_grids=(length-3)/3\n",
    "        assert start_time>365*86400*1000,\"start_time corrupt\"\n",
    "        assert end_time>365*86400*1000,\"end_time corrupt\"\n",
    "        all_accelerometer.append(a_[3:length])\n",
    "        all_time.append((start_time,(end_time-start_time)/data_grids))\n",
    "        a_=a_[length:]\n",
    "    lens=[len(v) for v in all_accelerometer]\n",
    "    print(f\"😊 data successfully chopped into {len(all_accelerometer)} pieces ,average length {sum(lens)/len(lens)}, min {min(lens)}, max {max(lens)}\")\n",
    "    return all_accelerometer,all_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "836164e9-a8a8-4bb7-8581-6886b3736c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#从原始信号中选出最能符合最多平滑周期约束的信号\n",
    "def shot(peaks_candidate,peak_index,i):\n",
    "    global DEBUG \n",
    "    t0=peak_index[i]\n",
    "    period=t0-peak_index[i-1]\n",
    "    assert period>1.0,\"bad period\"\n",
    "    shotted=[t0]\n",
    "    shotted_possible=[t0]\n",
    "    time_drift=0.15*period\n",
    "    #左向匹配\n",
    "    cur=t0-period\n",
    "    #if DEBUG :       print(f\"cur {cur} period {period}\")\n",
    "    while cur>=0:\n",
    "        #放这里而不是最后，避免下标越界\n",
    "        shotted_possible.append(int(cur))\n",
    "        \n",
    "        ib=max(0,int(cur-time_drift))\n",
    "        ie=min(len(peaks_candidate),int(cur+time_drift))\n",
    "        ind=np.argmax(peaks_candidate[ib:ie])\n",
    "        #print(f\"to left:ib {ib},ie {ie}, period {period},i {i} cur {cur} ind{ind}\")\n",
    "        if peaks_candidate[ib+ind]>0:\n",
    "            cur=ib+ind #接收现实的修正\n",
    "            shotted.append(int(cur))\n",
    "            shotted_possible[-1]=cur\n",
    "        cur-=period\n",
    "            \n",
    "    #向右匹配\n",
    "    cur=t0+period\n",
    "    while cur<len(peaks_candidate):\n",
    "        #放这里而不是最后，避免下标越界\n",
    "        shotted_possible.append(int(cur))\n",
    "        \n",
    "        ib=max(0,int(cur-time_drift))\n",
    "        ie=min(len(peaks_candidate),int(cur+time_drift))\n",
    "        ind=np.argmax(peaks_candidate[ib:ie])\n",
    "        #print(f\"to right:ib {ib},ie {ie}, period {period},i {i} cur {cur} ind{ind}\")\n",
    "        if peaks_candidate[ib+ind]>0:\n",
    "            cur=ib+ind #接收现实的修正\n",
    "            shotted.append(int(cur))\n",
    "            shotted_possible[-1]=cur\n",
    "        cur+=period\n",
    "    return shotted,shotted_possible\n",
    "def best_periodical(peaks_candidate):\n",
    "    peak_index=np.nonzero(peaks_candidate)[0]\n",
    "    assert len(peak_index)>10, \"peaks_candidate contains too less data points\"\n",
    "    \n",
    "    #假设任意两个峰值信号，作为心跳信号。分析这个假设下出现的心跳周期数\n",
    "    #every element contains tuple,which is (shotted,shotted_missed)\n",
    "    shoted_list=[shot(peaks_candidate,peak_index,i) for i in range(1,len(peak_index))]\n",
    "    duty_cycles=[ len(s[0])/len(peak_index)  for s in shoted_list]\n",
    "    \n",
    "    #print(f\"duty_cycles {duty_cycles} \")\n",
    "    #找出最大的心跳周期\n",
    "    maxind=np.argmax(np.array(duty_cycles))\n",
    "    #print(f\"duty_cycles len{len(duty_cycles)} maxind {maxind} max timespan {time_span[maxind]} duty_cycle {duty_cycles[maxind]} t0 {duty_cycles_states[maxind].t0}\")\n",
    "    \n",
    "    #把数据写回到时间序列\n",
    "    result=[0]*len(peaks_candidate)\n",
    "    for i in shoted_list[maxind][0]:\n",
    "        result[i]=peaks_candidate[i]\n",
    "        \n",
    "    possible=[0]*len(peaks_candidate)\n",
    "    maxv,l=np.max(peaks_candidate),len(shoted_list[maxind][1])\n",
    "    #print(\"shoted_list[maxind][1]\",shoted_list[maxind][1],f\"len of peaks_candidate {len(peaks_candidate)}\")\n",
    "    for i,vi in enumerate(shoted_list[maxind][1]):\n",
    "        #possible[vi]=peaks_candidate[vi]\n",
    "        possible[vi]=maxv*0.7*(i)/l +(maxv*0.3)\n",
    "    #print(f\"possible length {np.count_nonzero(possible)}\")\n",
    "    return result,possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "e3ad366c-60b6-48a2-b252-062e03acc738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickout_peak(data,grids_span):\n",
    "    value=[0]*len(data)\n",
    "    for i,v in enumerate(data):\n",
    "        l,r=max(0,int(i-grids_span)),min(int(i+grids_span),len(data))\n",
    "        assert r-l>1,\"can not peak out signal peak\"\n",
    "        j=np.argmax(data[l:r])\n",
    "        if j==i-l:\n",
    "            value[i]=v\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "d7c1914f-689d-49ba-803f-172ef4abc6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😊 data successfully chopped into 258 pieces ,average length 5399.186046511628, min 4101, max 5406\n",
      "saved to redis ,key:1651836110713 {37000.0}\n",
      "saved to redis ,key:1651836140835 {36000.0}\n",
      "saved to redis ,key:1651836170860 {34000.0}\n",
      "saved to redis ,key:1651836200904 {34000.0}\n",
      "saved to redis ,key:1651836230924 {35000.0}\n",
      "saved to redis ,key:1651836260956 {1133.8043582474686}\n",
      "saved to redis ,key:1651836290988 {35000.0}\n",
      "saved to redis ,key:1651843837355 {34000.0}\n",
      "saved to redis ,key:1651843867478 {34000.0}\n",
      "saved to redis ,key:1651843938536 {237.78735451237762}\n",
      "saved to redis ,key:1651843968657 {32000.0}\n",
      "saved to redis ,key:1651843998683 {32000.0}\n",
      "saved to redis ,key:1651844028729 {34000.0}\n",
      "saved to redis ,key:1651844058748 {946.6025092728122}\n",
      "saved to redis ,key:1651844088779 {32000.0}\n",
      "saved to redis ,key:1651844118795 {34000.0}\n",
      "saved to redis ,key:1651844148827 {32000.0}\n",
      "saved to redis ,key:1651844178859 {146.98344757121916}\n",
      "saved to redis ,key:1651844208902 {31000.0}\n",
      "saved to redis ,key:1651844238924 {32000.0}\n",
      "saved to redis ,key:1651844268956 {33000.0}\n",
      "saved to redis ,key:1651844299000 {33000.0}\n",
      "saved to redis ,key:1651844329020 {31000.0}\n",
      "saved to redis ,key:1651844359054 {142.36866175395502}\n",
      "saved to redis ,key:1651844389084 {33000.0}\n",
      "saved to redis ,key:1651844419116 {32000.0}\n",
      "saved to redis ,key:1651844449160 {32000.0}\n",
      "saved to redis ,key:1651844479181 {1007.1869503459462}\n",
      "saved to redis ,key:1651844509213 {272.4194008338182}\n",
      "saved to redis ,key:1651844539245 {31000.0}\n",
      "saved to redis ,key:1651844599309 {222.71418765714586}\n",
      "saved to redis ,key:1651844629342 {311.4935519895355}\n",
      "saved to redis ,key:1651844659373 {1007.1869503459462}\n",
      "saved to redis ,key:1651844749469 {157.98801740658584}\n",
      "saved to redis ,key:1651844779485 {311.4935519895355}\n",
      "saved to redis ,key:1651844809518 {291.63293207218095}\n",
      "saved to redis ,key:1651844839550 {157.98801740658584}\n",
      "saved to redis ,key:1651844869582 {272.4194008338182}\n",
      "saved to redis ,key:1651844899614 {124.9199445437042}\n",
      "saved to redis ,key:1651844929646 {100.86335891053233}\n",
      "saved to redis ,key:1651844959678 {291.63293207218095}\n",
      "saved to redis ,key:1651844989710 {457.7460626099167}\n",
      "saved to redis ,key:1651845079807 {488.0325217490457}\n",
      "saved to redis ,key:1651845139872 {32000.0}\n",
      "saved to redis ,key:1651845169903 {32000.0}\n",
      "saved to redis ,key:1651845199937 {31000.0}\n",
      "saved to redis ,key:1651845229967 {33000.0}\n",
      "saved to redis ,key:1651845260002 {32000.0}\n",
      "saved to redis ,key:1651845290032 {32000.0}\n",
      "saved to redis ,key:1651845320064 {33000.0}\n",
      "saved to redis ,key:1651845350096 {124.9199445437042}\n",
      "saved to redis ,key:1651845380128 {887.8412934319284}\n",
      "saved to redis ,key:1651845410173 {830.9086160259894}\n",
      "saved to redis ,key:1651845440192 {31000.0}\n",
      "saved to redis ,key:1651845470224 {33000.0}\n",
      "saved to redis ,key:1651845500256 {30000.0}\n",
      "saved to redis ,key:1651845530294 {32000.0}\n",
      "saved to redis ,key:1651845560321 {32000.0}\n",
      "saved to redis ,key:1651845590353 {33000.0}\n",
      "saved to redis ,key:1651845620385 {457.7460626099167}\n",
      "saved to redis ,key:1651845650417 {146.98344757121916}\n",
      "saved to redis ,key:1651845680449 {946.6025092728122}\n",
      "saved to redis ,key:1651845710481 {30000.0}\n",
      "saved to redis ,key:1651845740513 {32000.0}\n",
      "saved to redis ,key:1651845770530 {32000.0}\n",
      "saved to redis ,key:1651845800561 {32000.0}\n",
      "saved to redis ,key:1651845830593 {519.2729635781039}\n",
      "saved to redis ,key:1651845860625 {30000.0}\n",
      "saved to redis ,key:1651845890641 {31000.0}\n",
      "saved to redis ,key:1651845920673 {100.86335891053233}\n",
      "saved to redis ,key:1651845950705 {31000.0}\n",
      "saved to redis ,key:1651845980737 {253.8536019030033}\n",
      "saved to redis ,key:1651846010769 {372.62470391728476}\n",
      "saved to redis ,key:1651846220994 {291.63293207218095}\n",
      "saved to redis ,key:1651846251026 {157.98801740658584}\n",
      "saved to redis ,key:1651846311074 {946.6025092728122}\n",
      "saved to redis ,key:1651846371151 {100.86335891053233}\n",
      "saved to redis ,key:1651846431203 {488.0325217490457}\n",
      "saved to redis ,key:1651846491267 {33000.0}\n",
      "saved to redis ,key:1651846521299 {33000.0}\n",
      "saved to redis ,key:1651846551331 {946.6025092728122}\n",
      "saved to redis ,key:1651846581363 {33000.0}\n",
      "saved to redis ,key:1651846611395 {33000.0}\n",
      "saved to redis ,key:1651846641428 {108.59984484370743}\n",
      "saved to redis ,key:1651846671459 {428.41499695901246}\n",
      "saved to redis ,key:1651846701501 {31000.0}\n",
      "saved to redis ,key:1651846731524 {124.61694382378171}\n",
      "saved to redis ,key:1651846761556 {887.8412934319284}\n",
      "saved to redis ,key:1651846791601 {115.68109020594919}\n",
      "saved to redis ,key:1651846821620 {146.98344757121916}\n",
      "saved to redis ,key:1651846851653 {830.9086160259894}\n",
      "saved to redis ,key:1651846881685 {30000.0}\n",
      "saved to redis ,key:1651846911717 {32000.0}\n",
      "saved to redis ,key:1651846941749 {272.4194008338182}\n",
      "saved to redis ,key:1651847031845 {31000.0}\n",
      "saved to redis ,key:1651847061878 {208.12986065005708}\n",
      "saved to redis ,key:1651847212025 {107.07423818031788}\n",
      "saved to redis ,key:1651847332151 {180.4292004343364}\n",
      "saved to redis ,key:1651847362183 {116.33182828293226}\n",
      "saved to redis ,key:1651847392214 {253.8536019030033}\n",
      "saved to redis ,key:1651847452278 {30000.0}\n",
      "saved to redis ,key:1651847482310 {253.8536019030033}\n",
      "saved to redis ,key:1651847512343 {30000.0}\n",
      "saved to redis ,key:1651847572407 {830.9086160259894}\n",
      "saved to redis ,key:1651847602439 {372.62470391728476}\n",
      "saved to redis ,key:1651847632471 {107.07423818031788}\n",
      "saved to redis ,key:1651847662505 {400.04073850892036}\n",
      "saved to redis ,key:1651847692536 {830.9086160259894}\n",
      "saved to redis ,key:1651847722568 {200.02036925446018}\n",
      "saved to redis ,key:1651847752610 {372.62470391728476}\n",
      "saved to redis ,key:1651847782632 {400.04073850892036}\n",
      "saved to redis ,key:1651847812664 {253.8536019030033}\n",
      "saved to redis ,key:1651932804066 {457.7460626099167}\n",
      "saved to redis ,key:1651932834186 {32000.0}\n",
      "saved to redis ,key:1651932864213 {272.4194008338182}\n",
      "saved to redis ,key:1651932894245 {194.03474181072247}\n",
      "saved to redis ,key:1651932924289 {31000.0}\n",
      "saved to redis ,key:1651932954309 {115.68109020594919}\n",
      "saved to redis ,key:1651932984341 {107.07423818031788}\n",
      "saved to redis ,key:1651933014356 {30000.0}\n",
      "saved to redis ,key:1651933044389 {32000.0}\n",
      "saved to redis ,key:1651933074421 {32000.0}\n",
      "saved to redis ,key:1651933104453 {946.6025092728122}\n",
      "saved to redis ,key:1651933134485 {32000.0}\n",
      "saved to redis ,key:1651933164517 {31000.0}\n",
      "saved to redis ,key:1651933194550 {32000.0}\n",
      "saved to redis ,key:1651933224581 {31000.0}\n",
      "saved to redis ,key:1651933254620 {32000.0}\n",
      "saved to redis ,key:1651933284646 {32000.0}\n",
      "saved to redis ,key:1651933314679 {1069.5893240432908}\n",
      "saved to redis ,key:1651933344710 {31000.0}\n",
      "saved to redis ,key:1651933374742 {31000.0}\n",
      "saved to redis ,key:1651933404779 {31000.0}\n",
      "saved to redis ,key:1651933434806 {32000.0}\n",
      "saved to redis ,key:1651933464822 {30000.0}\n",
      "saved to redis ,key:1651933494854 {31000.0}\n",
      "saved to redis ,key:1651933524886 {31000.0}\n",
      "saved to redis ,key:1651933554918 {31000.0}\n",
      "saved to redis ,key:1651933584951 {488.0325217490457}\n",
      "saved to redis ,key:1651933614983 {30000.0}\n",
      "saved to redis ,key:1651933645014 {291.63293207218095}\n",
      "saved to redis ,key:1651933675030 {30000.0}\n",
      "saved to redis ,key:1651933705062 {31000.0}\n",
      "saved to redis ,key:1651933735094 {124.61694382378171}\n",
      "saved to redis ,key:1651933765126 {830.9086160259894}\n",
      "saved to redis ,key:1651933795159 {31000.0}\n",
      "saved to redis ,key:1651933825191 {272.4194008338182}\n",
      "saved to redis ,key:1651933855223 {194.03474181072247}\n",
      "saved to redis ,key:1651933885255 {31000.0}\n",
      "saved to redis ,key:1651933915287 {30000.0}\n",
      "saved to redis ,key:1651933945320 {31000.0}\n",
      "saved to redis ,key:1651933975352 {291.63293207218095}\n",
      "saved to redis ,key:1651934005383 {30000.0}\n",
      "saved to redis ,key:1651934035416 {400.04073850892036}\n",
      "saved to redis ,key:1651934065447 {400.04073850892036}\n",
      "saved to redis ,key:1651934095463 {30000.0}\n",
      "saved to redis ,key:1651934125495 {29000.0}\n",
      "saved to redis ,key:1651934185561 {30000.0}\n",
      "saved to redis ,key:1651934215593 {253.8536019030033}\n",
      "saved to redis ,key:1651934245624 {31000.0}\n",
      "saved to redis ,key:1651934275660 {830.9086160259894}\n",
      "saved to redis ,key:1651934305688 {167.31360690431833}\n",
      "saved to redis ,key:1651934335720 {30000.0}\n",
      "saved to redis ,key:1651934365753 {146.98344757121916}\n",
      "saved to redis ,key:1651934395785 {124.61694382378171}\n",
      "saved to redis ,key:1651934425817 {235.93618013679844}\n",
      "saved to redis ,key:1651934455851 {30000.0}\n",
      "saved to redis ,key:1651934485881 {31000.0}\n",
      "saved to redis ,key:1651934515913 {30000.0}\n",
      "saved to redis ,key:1651934545945 {116.33182828293226}\n",
      "saved to redis ,key:1651934575977 {29000.0}\n",
      "saved to redis ,key:1651934606017 {30000.0}\n",
      "saved to redis ,key:1651934636042 {30000.0}\n",
      "saved to redis ,key:1651934666074 {29000.0}\n",
      "saved to redis ,key:1651934696106 {775.8098109578268}\n",
      "saved to redis ,key:1651934726138 {28000.0}\n",
      "saved to redis ,key:1651934786204 {28000.0}\n",
      "saved to redis ,key:1651934816235 {29000.0}\n",
      "saved to redis ,key:1651934846266 {28000.0}\n",
      "saved to redis ,key:1651934876298 {235.93618013679844}\n",
      "saved to redis ,key:1651934906331 {28000.0}\n",
      "saved to redis ,key:1651934936363 {29000.0}\n",
      "saved to redis ,key:1651934966395 {27000.0}\n",
      "saved to redis ,key:1651934996427 {154.6883328305175}\n",
      "saved to redis ,key:1651935026459 {27000.0}\n",
      "saved to redis ,key:1651935056491 {29000.0}\n",
      "saved to redis ,key:1651935086527 {29000.0}\n",
      "saved to redis ,key:1651935116558 {202.04905412105646}\n",
      "saved to redis ,key:1651935146588 {775.8098109578268}\n",
      "saved to redis ,key:1651935176620 {27000.0}\n",
      "saved to redis ,key:1651935206652 {29000.0}\n",
      "saved to redis ,key:1651935236684 {722.5502329377356}\n",
      "saved to redis ,key:1651935266716 {28000.0}\n",
      "saved to redis ,key:1651935296749 {27000.0}\n",
      "saved to redis ,key:1651935326781 {28000.0}\n",
      "saved to redis ,key:1651935356813 {27000.0}\n",
      "saved to redis ,key:1651935386846 {27000.0}\n",
      "saved to redis ,key:1651935416877 {722.5502329377356}\n",
      "saved to redis ,key:1651935476941 {28000.0}\n",
      "saved to redis ,key:1651935506982 {722.5502329377356}\n",
      "saved to redis ,key:1651935537005 {671.1352575928605}\n",
      "saved to redis ,key:1651935567022 {671.1352575928605}\n",
      "saved to redis ,key:1651935597053 {296.14015485118034}\n",
      "saved to redis ,key:1651935627085 {27000.0}\n",
      "saved to redis ,key:1651935657118 {671.1352575928605}\n",
      "saved to redis ,key:1651935687169 {116.33182828293226}\n",
      "saved to redis ,key:1651935717199 {142.55375122004557}\n",
      "saved to redis ,key:1651935747230 {27000.0}\n",
      "saved to redis ,key:1651935777263 {671.1352575928605}\n",
      "saved to redis ,key:1651935807295 {27000.0}\n",
      "saved to redis ,key:1651955511906 {27000.0}\n",
      "saved to redis ,key:1651955541923 {671.1352575928605}\n",
      "saved to redis ,key:1651955571955 {621.5702815791674}\n",
      "saved to redis ,key:1651955601988 {130.9102366901405}\n",
      "saved to redis ,key:1651955632020 {320.6729878882364}\n",
      "saved to redis ,key:1651955662052 {621.5702815791674}\n",
      "saved to redis ,key:1651955692084 {25000.0}\n",
      "saved to redis ,key:1651955722116 {25000.0}\n",
      "saved to redis ,key:1651955752148 {621.5702815791674}\n",
      "saved to redis ,key:1651955812196 {25000.0}\n",
      "saved to redis ,key:1651955842228 {25000.0}\n",
      "saved to redis ,key:1651955872260 {25000.0}\n",
      "saved to redis ,key:1651955902292 {26000.0}\n",
      "saved to redis ,key:1651955932324 {25000.0}\n",
      "😊 data successfully chopped into 2 pieces ,average length 5287.5, min 5169, max 5406\n",
      "saved to redis ,key:1651955992389 {528.012020007127}\n",
      "Job completed!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "DEBUG=False\n",
    "# 60*1000/220=272,272,60*1000/39=1538,1538  \n",
    "scan_iteration_foreach_window,time_window_min,time_window_max = 5,(60*1000/220)*0.9,(60*1000/39)*0.9\n",
    "# x^scan_iteration_foreach_window=time_window_max/time_window_min,ig. 1538/272\n",
    "factor=math.exp(math.log(time_window_max/time_window_min)/(scan_iteration_foreach_window-1))\n",
    "time_windows=[round(time_window_min*math.pow(factor,i)) for i in range(scan_iteration_foreach_window)]\n",
    "def labeling_heart_beat(accelerations,time_info):  \n",
    "    global DEBUG \n",
    "    startTime,timespan=time_info[0],time_info[1]\n",
    "    \n",
    "    #密度太稀疏，一秒钟40个数据点以上的不要\n",
    "    if timespan>25:\n",
    "        return\n",
    "    # if not startTime in  [1651932984341,1651933735094,1651934155535,1651934756171,1651955481794,1651955782167,1651955962357,1651935446909]:\n",
    "    #     return\n",
    "    if rds_to.exists(str(startTime)): return True    \n",
    "    \n",
    "    x,y,z=accelerations[0::3],accelerations[1::3],accelerations[2::3] #axis is x or y or z\n",
    "    assert len(accelerations)%3==0 and len(x)== len(y) and len(y)==len(z),\"data corrupt! check pls\"    \n",
    "    a=[math.sqrt(v**2+y[i]**2+z[i]**2) for i,v in enumerate(x)  ]\n",
    "    \n",
    "    best_score=-1\n",
    "    Periodical=[]\n",
    "    bestAxis=[]\n",
    "    channelI=-1\n",
    "    bestSpans=-1       \n",
    "    \n",
    "    for span in time_windows: \n",
    "        for channel,axis in enumerate([x,y,z,a]): #axis is x or y or z  \n",
    "            #DEBUG= (channel == 2) and (span == 583)\n",
    "    \n",
    "            absaxis=np.array([abs(v) for v in axis],dtype=\"float32\")\n",
    "            #print(f\"absaxis {absaxis.tolist()} len {len(absaxis)} span {span} timespan{timespan} \")\n",
    "            peaks_candidate=pickout_peak(absaxis,span/timespan)\n",
    "            num_peak=np.count_nonzero(peaks_candidate)\n",
    "            if num_peak<15: continue\n",
    "            peaks_periodical,peak_possible=best_periodical(peaks_candidate)\n",
    "            num_periodical=np.count_nonzero(peaks_periodical)\n",
    "            num_possible=np.count_nonzero(peak_possible)\n",
    "            #print(f\"peaks_periodical num {num_periodical} from num_peak {num_peak} num_possible {num_possible}\")\n",
    "            if num_periodical<10: continue\n",
    "            #要求num_possible 和 num_periodical 尽可能一致，做log 惩罚\n",
    "            #print(f\"num_possible/num_periodical {num_possible} {num_periodical} {num_possible/num_periodical}\")\n",
    "            score=num_periodical/(np.log(num_possible/num_periodical)+0.001)\n",
    "            #score=num_periodical/np.exp(num_possible/num_periodical)\n",
    "#             #插值补充点\n",
    "            #believable_added=add_believable_data(peaks_periodical,axis,time)            \n",
    "            \n",
    "            #得分100以下可能不准确，不保留结果\n",
    "            if score<100:\n",
    "                continue\n",
    "            if score>=best_score:\n",
    "                best_score=score\n",
    "                Periodical=peak_possible\n",
    "                channelI=channel\n",
    "                bestAxis=axis\n",
    "                bestSpans=span   \n",
    "    if best_score>0:\n",
    "        time=[timespan*i for i in range(len(bestAxis))]\n",
    "        label= [1 if v!=0 else 0 for v in Periodical]\n",
    "        \n",
    "        rds_to.set(str(startTime), json.dumps({\"accelero\":accelerations,\"start\":startTime,\"timespan\":timespan,\"label\":label}))        \n",
    "        print(f\"saved to redis ,key:{startTime}\",{best_score})\n",
    "       \n",
    "        # plt.figure(startTime,figsize=(30, 6))\n",
    "        # plt.xlabel(f\"data {startTime} ,channel ${channelI}\"+f\",bestSpans ${bestSpans}\"+f\",best_score{best_score} \")\n",
    "        # plt.plot(time,bestAxis)\n",
    "        # plt.plot(time,Periodical)\n",
    "    \n",
    "rds_to = redis.StrictRedis(host='docker.vm', port=6379, db=15)\n",
    "data_source=get_raw_data() \n",
    "cnt=0\n",
    "while True:\n",
    "    accelerations,time_span= next(data_source)   \n",
    "    if accelerations == None or time_span==None:break  \n",
    "    # cnt+=1\n",
    "    # if cnt%37!=0:\n",
    "    #     continue\n",
    "    labeling_heart_beat(accelerations,time_span) \n",
    "print(\"Job completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
